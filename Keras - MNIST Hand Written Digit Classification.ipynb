{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load The Keras dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 5s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets.mnist import load_data\n",
    "\n",
    "# load the data - it returns 2 tuples of digits & labels - one for\n",
    "# the train set & the other for the test set\n",
    "(train_digits, train_labels), (test_digits, test_labels) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 9, 0, 4, 6, 3, 8, 5, 3, 6, 8, 7, 7, 9], dtype=uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display 14 random images from the training set\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# to fix the randomization\n",
    "np.random.seed(123)\n",
    "#random generation of integer values\n",
    "rand_14 = np.random.randint(0, train_digits.shape[0],14)\n",
    "sample_digits = train_digits[rand_14]\n",
    "sample_labels = train_labels[rand_14]\n",
    "sample_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 120, 255, 247,  57,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 192, 253, 253, 123,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 192, 243, 177,  87,   0,   0,\n",
       "          0,   0,   0,  48, 213, 127,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 192, 226,  23,   0,   0,   0,\n",
       "          0,   0,   6, 168, 253, 228,  26,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 192, 253, 121,   0,   0,   0,\n",
       "          0,   0,  28, 253, 253, 253,  34,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 192, 253, 248,  74,   0,   0,\n",
       "          0,   0, 110, 253, 253, 253,  34,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 122, 253, 253, 190,   3,   0,\n",
       "          0,   0, 165, 253, 253, 253,  34,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   2, 115, 253, 253, 248, 125,\n",
       "         21,  21, 203, 253, 253, 152,   1,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   4, 114, 253, 253, 253,\n",
       "        232, 232, 253, 253, 209,  23,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   3, 119, 184, 184,\n",
       "        203, 253, 253, 253, 129,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         19, 103, 253, 253, 129,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  49, 253, 249,  46,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  49, 253, 246,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  49, 253, 246,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  49, 253, 246,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  49, 253, 246,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  37, 232, 246,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0, 165, 251, 112,  42,  42,   9,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0, 151, 244, 253, 253, 246,  50,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,  70, 253, 123,  79,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_digits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_digits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,4))\n",
    "for index, (image, label) in enumerate(zip(train_digits[10:15], train_labels[10:15])):\n",
    "    # 1 row & 5 columns\n",
    "    plt.subplot(1, 5, index + 1)\n",
    "    plt.imshow(np.reshape(image, (28,28)), cmap='Greys') # cmap = color map \n",
    "    plt.title('Training: %i\\n' % label, fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_digits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some variables...\n",
    "image_height = train_digits.shape[1]  \n",
    "image_width = train_digits.shape[2]\n",
    "num_channels = 1  # we have grayscale images\n",
    "# NOTE: image_height == image_width == 28\n",
    "\n",
    "# re-shape the images data - Preprocessing\n",
    "# Reshape is used to cahnge the dimentions of data\n",
    "train_data = np.reshape(train_digits, (train_digits.shape[0], \n",
    "                                       image_height, image_width, num_channels))\n",
    "test_data = np.reshape(test_digits, (test_digits.shape[0],\n",
    "                                     image_height, image_width, num_channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.zeros((10,2))\n",
    "a.shape\n",
    "b = np.reshape(a,(4,5))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-scale the image data to values between (0.0,1.0]\n",
    "# pre-processing : normalizing the image pixels\n",
    "train_data = train_data.astype('float32') / 255.\n",
    "test_data = test_data.astype('float32') / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 10), (10000, 10))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-hot encode the labels - we have 10 output classes\n",
    "# so 3 -> [0 0 0 1 0 0 0 0 0 0], 5 -> [0 0 0 0 0 1 0 0 0 0] & so on\n",
    "[3,5,7]\n",
    "'''[[0 0 0 1 0 0 0 0 0 0]\n",
    "    [0 0 0 0 0 1 0 0 0 0]  \n",
    "    [0 0 0 0 0 0 0 1 0 0]]''' \n",
    "\n",
    "from keras.utils import to_categorical\n",
    "num_classes = 10\n",
    "train_labels_cat = to_categorical(train_labels,num_classes)\n",
    "test_labels_cat = to_categorical(test_labels,num_classes)\n",
    "train_labels_cat.shape, test_labels_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the training dataset (5 times!)\n",
    "for _ in range(5): \n",
    "    indexes = np.random.permutation(len(train_data))\n",
    "\n",
    "train_data = train_data[indexes]\n",
    "train_labels_cat = train_labels_cat[indexes]\n",
    "# now set-aside 10% of the train_data/labels as the\n",
    "# cross-validation sets\n",
    "val_perc = 0.10\n",
    "val_count = int(val_perc * len(train_data))\n",
    "\n",
    "# first pick validation set from train_data/labels\n",
    "val_data = train_data[:val_count,:]\n",
    "val_labels_cat = train_labels_cat[:val_count,:]\n",
    "\n",
    "# leave rest in training set\n",
    "train_data2 = train_data[val_count:,:]\n",
    "train_labels_cat2 = train_labels_cat[val_count:,:]\n",
    "\n",
    "# NOTE: We will train on train_data2/train_labels_cat2 and \n",
    "# cross-validate on val_data/val_labels_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jishn\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               73856     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 130,890\n",
      "Trainable params: 130,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow import keras\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    # add Convolutional layers\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu', \n",
    "                     padding='same',\n",
    "                     input_shape=(image_height, image_width, num_channels)))\n",
    "    \n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu', \n",
    "                     padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu', \n",
    "                     padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))    \n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    ## Neural Network to Train with Image data\n",
    "    # Densely connected layers\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    # output layer\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    # compile with adam optimizer & categorical_crossentropy loss function\n",
    "    ## ylog(p) + (1-y) log (1-p) where p is predicted observation of class c\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jishn\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 61s 1ms/step - loss: 0.1761 - accuracy: 0.9456 - val_loss: 0.0594 - val_accuracy: 0.9802\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 58s 1ms/step - loss: 0.0468 - accuracy: 0.9857 - val_loss: 0.0419 - val_accuracy: 0.9860\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 58s 1ms/step - loss: 0.0340 - accuracy: 0.9894 - val_loss: 0.0363 - val_accuracy: 0.9885\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 63s 1ms/step - loss: 0.0257 - accuracy: 0.9918 - val_loss: 0.0281 - val_accuracy: 0.9913\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 62s 1ms/step - loss: 0.0203 - accuracy: 0.9936 - val_loss: 0.0370 - val_accuracy: 0.9878\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 66s 1ms/step - loss: 0.0173 - accuracy: 0.9940 - val_loss: 0.0308 - val_accuracy: 0.9898\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 67s 1ms/step - loss: 0.0133 - accuracy: 0.9958 - val_loss: 0.0359 - val_accuracy: 0.9897\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 63s 1ms/step - loss: 0.0115 - accuracy: 0.9962 - val_loss: 0.0329 - val_accuracy: 0.9902\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 61s 1ms/step - loss: 0.0101 - accuracy: 0.9965 - val_loss: 0.0533 - val_accuracy: 0.9872\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 66s 1ms/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.0432 - val_accuracy: 0.9892\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 63s 1ms/step - loss: 0.0097 - accuracy: 0.9966 - val_loss: 0.0350 - val_accuracy: 0.9913\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 64s 1ms/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.0516 - val_accuracy: 0.9887\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 63s 1ms/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 0.0618 - val_accuracy: 0.9845\n",
      "Epoch 14/15\n",
      "20672/54000 [==========>...................] - ETA: 37s - loss: 0.0037 - accuracy: 0.9988"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-2035052ac465>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m results = model.fit(train_data2, train_labels_cat2, \n\u001b[0;32m      2\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m                     validation_data=(val_data, val_labels_cat))\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3074\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3076\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# A keyboard interrupt is made to limit the output being generated. While executing, kindly make sure you run it till the end\n",
    "results = model.fit(train_data2, train_labels_cat2, \n",
    "                    epochs=15, batch_size=64,\n",
    "                    validation_data=(val_data, val_labels_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display plots...\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.show(results.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = \\\n",
    "  model.evaluate(test_data, test_labels_cat, batch_size=64)\n",
    "print('Test loss: %.4f accuracy: %.4f' % (test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_data)\n",
    "first20_preds = np.argmax(predictions, axis=1)[:25]\n",
    "first20_true = np.argmax(test_labels_cat,axis=1)[:25]\n",
    "print(first20_preds)\n",
    "print(first20_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many mismatches?\n",
    "# wrong predictions\n",
    "(np.argmax(predictions, axis=1) != np.argmax(test_labels_cat,axis=1)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img = cv2.imread('E:/Opencv/image2.png',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.resize(img, (28, 28))\n",
    "img = cv2.bitwise_not(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img.reshape(28, 28),cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(img.reshape(1, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(pred, axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
